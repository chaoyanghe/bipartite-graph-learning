Sat, 18 May 2019 11:05:36 utils.py[line:43] INFO class map loaded
Sat, 18 May 2019 11:05:36 utils.py[line:59] INFO bad nodes removed
Sat, 18 May 2019 11:05:36 utils.py[line:78] INFO Normalized
Sat, 18 May 2019 11:05:37 utils.py[line:93] INFO data all loaded
Sat, 18 May 2019 11:05:37 unsupervised_train.py[line:439] INFO start training
Sat, 18 May 2019 11:05:37 unsupervised_train.py[line:188] INFO edge minibatch
Sat, 18 May 2019 11:05:37 deprecation.py[line:323] WARNING From /Users/apple/Documents/P1_Decentralized_Multitask/Leaf_New_2.0/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Sat, 18 May 2019 11:05:37 unsupervised_train.py[line:198] INFO choose model
Sat, 18 May 2019 11:05:37 deprecation.py[line:506] WARNING From /Users/apple/Documents/P4_Graph/merge_sourcecode/bipartite-graph-learning/GraphSage/graphsage/aggregators.py:46: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Sat, 18 May 2019 11:05:38 deprecation.py[line:323] WARNING From /Users/apple/Documents/P4_Graph/merge_sourcecode/bipartite-graph-learning/GraphSage/graphsage/models.py:407: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
Sat, 18 May 2019 11:05:38 deprecation.py[line:323] WARNING From /Users/apple/Documents/P1_Decentralized_Multitask/Leaf_New_2.0/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Sat, 18 May 2019 11:05:39 unsupervised_train.py[line:310] INFO training epoch: 1
Sat, 18 May 2019 11:05:49 unsupervised_train.py[line:352] INFO Iter: 0000, train_loss=19.051903, train_mrr=0.248266, train_mrr_ema=0.248266, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=10.356115
Sat, 18 May 2019 11:05:49 unsupervised_train.py[line:354] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0000, max_total_steps: 100000000
Sat, 18 May 2019 11:06:29 unsupervised_train.py[line:352] INFO Iter: 0010, train_loss=17.618677, train_mrr=0.297694, train_mrr_ema=0.249678, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.500001
Sat, 18 May 2019 11:06:29 unsupervised_train.py[line:354] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0010, max_total_steps: 100000000
Sat, 18 May 2019 11:07:27 unsupervised_train.py[line:352] INFO Iter: 0020, train_loss=17.616825, train_mrr=0.310741, train_mrr_ema=0.252027, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=5.119544
Sat, 18 May 2019 11:07:27 unsupervised_train.py[line:354] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0020, max_total_steps: 100000000
Sat, 18 May 2019 11:08:09 unsupervised_train.py[line:352] INFO Iter: 0030, train_loss=17.070360, train_mrr=0.280703, train_mrr_ema=0.253543, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.846267
Sat, 18 May 2019 11:08:09 unsupervised_train.py[line:354] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0030, max_total_steps: 100000000
Sat, 18 May 2019 11:08:52 unsupervised_train.py[line:352] INFO Iter: 0040, train_loss=16.953299, train_mrr=0.262264, train_mrr_ema=0.256692, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.713541
Sat, 18 May 2019 11:08:52 unsupervised_train.py[line:354] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0040, max_total_steps: 100000000
Sat, 18 May 2019 11:09:33 unsupervised_train.py[line:352] INFO Iter: 0050, train_loss=15.943864, train_mrr=0.309649, train_mrr_ema=0.259252, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.592686
Sat, 18 May 2019 11:09:33 unsupervised_train.py[line:354] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0050, max_total_steps: 100000000
Sat, 18 May 2019 11:10:27 unsupervised_train.py[line:352] INFO Iter: 0060, train_loss=15.879181, train_mrr=0.310809, train_mrr_ema=0.262405, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.712120
Sat, 18 May 2019 11:10:27 unsupervised_train.py[line:354] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0060, max_total_steps: 100000000
Sat, 18 May 2019 11:11:07 unsupervised_train.py[line:352] INFO Iter: 0070, train_loss=16.004265, train_mrr=0.303973, train_mrr_ema=0.266023, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.622862
Sat, 18 May 2019 11:11:07 unsupervised_train.py[line:354] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0070, max_total_steps: 100000000
Sat, 18 May 2019 11:11:58 unsupervised_train.py[line:352] INFO Iter: 0080, train_loss=15.795763, train_mrr=0.305012, train_mrr_ema=0.268863, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.677562
Sat, 18 May 2019 11:11:58 unsupervised_train.py[line:354] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0080, max_total_steps: 100000000
Sat, 18 May 2019 11:12:55 unsupervised_train.py[line:352] INFO Iter: 0090, train_loss=15.426096, train_mrr=0.309222, train_mrr_ema=0.272423, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.792039
Sat, 18 May 2019 11:12:55 unsupervised_train.py[line:354] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0090, max_total_steps: 100000000
Sat, 18 May 2019 11:13:50 unsupervised_train.py[line:352] INFO Iter: 0100, train_loss=15.022837, train_mrr=0.330687, train_mrr_ema=0.276045, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.857367
Sat, 18 May 2019 11:13:50 unsupervised_train.py[line:354] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0100, max_total_steps: 100000000
Sat, 18 May 2019 11:14:39 unsupervised_train.py[line:352] INFO Iter: 0110, train_loss=15.275136, train_mrr=0.305497, train_mrr_ema=0.279178, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.860294
Sat, 18 May 2019 11:14:39 unsupervised_train.py[line:354] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0110, max_total_steps: 100000000
Sat, 18 May 2019 11:15:40 unsupervised_train.py[line:352] INFO Iter: 0120, train_loss=15.260620, train_mrr=0.308945, train_mrr_ema=0.282497, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.960837
Sat, 18 May 2019 11:15:40 unsupervised_train.py[line:354] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0120, max_total_steps: 100000000
Sat, 18 May 2019 11:16:42 unsupervised_train.py[line:352] INFO Iter: 0130, train_loss=15.197506, train_mrr=0.308601, train_mrr_ema=0.285827, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=5.059144
Sat, 18 May 2019 11:16:42 unsupervised_train.py[line:354] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0130, max_total_steps: 100000000
Sat, 18 May 2019 11:17:31 unsupervised_train.py[line:352] INFO Iter: 0140, train_loss=15.243976, train_mrr=0.317901, train_mrr_ema=0.290189, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=5.047568
Sat, 18 May 2019 11:17:31 unsupervised_train.py[line:354] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0140, max_total_steps: 100000000
Sat, 18 May 2019 11:18:28 unsupervised_train.py[line:352] INFO Iter: 0150, train_loss=15.014772, train_mrr=0.309091, train_mrr_ema=0.292275, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=5.090287
Sat, 18 May 2019 11:18:28 unsupervised_train.py[line:354] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0150, max_total_steps: 100000000
Sat, 18 May 2019 11:19:43 unsupervised_train.py[line:352] INFO Iter: 0160, train_loss=15.395368, train_mrr=0.290327, train_mrr_ema=0.294877, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=5.242161
Sat, 18 May 2019 11:19:43 unsupervised_train.py[line:354] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0160, max_total_steps: 100000000
Sat, 18 May 2019 11:20:29 unsupervised_train.py[line:352] INFO Iter: 0170, train_loss=14.938426, train_mrr=0.298637, train_mrr_ema=0.296715, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=5.204984
Sat, 18 May 2019 11:20:29 unsupervised_train.py[line:354] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0170, max_total_steps: 100000000
Sat, 18 May 2019 11:21:11 unsupervised_train.py[line:352] INFO Iter: 0180, train_loss=14.889063, train_mrr=0.345943, train_mrr_ema=0.300117, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=5.145714
Sat, 18 May 2019 11:21:11 unsupervised_train.py[line:354] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0180, max_total_steps: 100000000
Sat, 18 May 2019 11:21:52 unsupervised_train.py[line:352] INFO Iter: 0190, train_loss=14.600107, train_mrr=0.363584, train_mrr_ema=0.302414, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=5.093688
Sat, 18 May 2019 11:21:52 unsupervised_train.py[line:354] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0190, max_total_steps: 100000000
Sat, 18 May 2019 11:22:35 unsupervised_train.py[line:352] INFO Iter: 0200, train_loss=14.825568, train_mrr=0.332538, train_mrr_ema=0.305481, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=5.052588
Sat, 18 May 2019 11:22:35 unsupervised_train.py[line:354] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0200, max_total_steps: 100000000
Sat, 18 May 2019 11:23:15 unsupervised_train.py[line:352] INFO Iter: 0210, train_loss=14.941353, train_mrr=0.341594, train_mrr_ema=0.307902, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=5.003440
Sat, 18 May 2019 11:23:15 unsupervised_train.py[line:354] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0210, max_total_steps: 100000000
Sat, 18 May 2019 11:23:56 unsupervised_train.py[line:352] INFO Iter: 0220, train_loss=14.939724, train_mrr=0.354703, train_mrr_ema=0.310799, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.962645
Sat, 18 May 2019 11:23:56 unsupervised_train.py[line:354] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0220, max_total_steps: 100000000
Sat, 18 May 2019 11:24:29 unsupervised_train.py[line:375] INFO ######## Saving embedding data to file ##########
Sat, 18 May 2019 11:24:33 unsupervised_train.py[line:129] INFO Start saving embedding for succeed tasks
Sat, 18 May 2019 11:24:33 unsupervised_train.py[line:147] INFO Number of nodes in set U: 734
Sat, 18 May 2019 11:24:33 unsupervised_train.py[line:429] INFO ############ Embedding data saved #############
Sat, 18 May 2019 12:35:56 utils.py[line:43] INFO class map loaded
Sat, 18 May 2019 12:35:56 utils.py[line:59] INFO bad nodes removed
Sat, 18 May 2019 12:35:57 utils.py[line:78] INFO Normalized
Sat, 18 May 2019 12:35:57 utils.py[line:93] INFO data all loaded
Sat, 18 May 2019 12:35:57 unsupervised_train.py[line:440] INFO start training
Sat, 18 May 2019 12:35:57 unsupervised_train.py[line:189] INFO edge minibatch
Sat, 18 May 2019 12:35:57 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/10.Federated-Learning-with-DPASGD/sourcecode/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Sat, 18 May 2019 12:35:58 unsupervised_train.py[line:199] INFO choose model
Sat, 18 May 2019 12:35:58 deprecation.py[line:506] WARNING From /Users/chaoyanghe/Presentation/12.GraphNeuralNetwork/sourcecode/bipartite-graph-learning/GraphSage/graphsage/aggregators.py:46: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Sat, 18 May 2019 12:35:58 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/12.GraphNeuralNetwork/sourcecode/bipartite-graph-learning/GraphSage/graphsage/models.py:407: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
Sat, 18 May 2019 12:35:58 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/10.Federated-Learning-with-DPASGD/sourcecode/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Sat, 18 May 2019 12:35:59 unsupervised_train.py[line:311] INFO training epoch: 1
Sat, 18 May 2019 12:36:04 unsupervised_train.py[line:353] INFO Iter: 0000, train_loss=18.627205, train_mrr=0.271067, train_mrr_ema=0.271067, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=5.426571
Sat, 18 May 2019 12:36:04 unsupervised_train.py[line:355] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0000, max_total_steps: 100000000
