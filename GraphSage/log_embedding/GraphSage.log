Sat, 18 May 2019 13:11:47 utils.py[line:43] INFO class map loaded
Sat, 18 May 2019 13:11:47 utils.py[line:59] INFO bad nodes removed
Sat, 18 May 2019 13:11:47 utils.py[line:78] INFO Normalized
Sat, 18 May 2019 13:11:48 utils.py[line:93] INFO data all loaded
Sat, 18 May 2019 13:11:48 unsupervised_train.py[line:440] INFO start training
Sat, 18 May 2019 13:11:48 unsupervised_train.py[line:189] INFO edge minibatch
Sat, 18 May 2019 13:11:48 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/10.Federated-Learning-with-DPASGD/sourcecode/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Sat, 18 May 2019 13:11:48 unsupervised_train.py[line:199] INFO choose model
Sat, 18 May 2019 13:11:48 deprecation.py[line:506] WARNING From /Users/chaoyanghe/Presentation/12.GraphNeuralNetwork/sourcecode/bipartite-graph-learning/GraphSage/graphsage/aggregators.py:46: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Sat, 18 May 2019 13:11:49 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/12.GraphNeuralNetwork/sourcecode/bipartite-graph-learning/GraphSage/graphsage/models.py:407: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
Sat, 18 May 2019 13:11:49 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/10.Federated-Learning-with-DPASGD/sourcecode/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Sat, 18 May 2019 13:11:50 unsupervised_train.py[line:311] INFO training epoch: 1
Sat, 18 May 2019 13:11:54 unsupervised_train.py[line:353] INFO Iter: 0000, train_loss=18.920454, train_mrr=0.235607, train_mrr_ema=0.235607, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.579267
Sat, 18 May 2019 13:11:54 unsupervised_train.py[line:355] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0000, max_total_steps: 100000000
Sat, 18 May 2019 13:12:26 unsupervised_train.py[line:353] INFO Iter: 0010, train_loss=17.543880, train_mrr=0.314305, train_mrr_ema=0.239139, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.314407
Sat, 18 May 2019 13:12:26 unsupervised_train.py[line:355] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0010, max_total_steps: 100000000
Sat, 18 May 2019 13:15:34 utils.py[line:43] INFO class map loaded
Sat, 18 May 2019 13:15:34 utils.py[line:59] INFO bad nodes removed
Sat, 18 May 2019 13:15:34 utils.py[line:78] INFO Normalized
Sat, 18 May 2019 13:15:35 utils.py[line:93] INFO data all loaded
Sat, 18 May 2019 13:15:35 unsupervised_train.py[line:440] INFO start training
Sat, 18 May 2019 13:15:35 unsupervised_train.py[line:189] INFO edge minibatch
Sat, 18 May 2019 13:15:35 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/10.Federated-Learning-with-DPASGD/sourcecode/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Sat, 18 May 2019 13:15:35 unsupervised_train.py[line:199] INFO choose model
Sat, 18 May 2019 13:15:35 deprecation.py[line:506] WARNING From /Users/chaoyanghe/Presentation/12.GraphNeuralNetwork/sourcecode/bipartite-graph-learning/GraphSage/graphsage/aggregators.py:46: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Sat, 18 May 2019 13:15:36 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/12.GraphNeuralNetwork/sourcecode/bipartite-graph-learning/GraphSage/graphsage/models.py:407: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
Sat, 18 May 2019 13:15:36 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/10.Federated-Learning-with-DPASGD/sourcecode/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Sat, 18 May 2019 13:15:37 unsupervised_train.py[line:311] INFO training epoch: 1
Sat, 18 May 2019 13:15:41 unsupervised_train.py[line:353] INFO Iter: 0000, train_loss=18.926439, train_mrr=0.243837, train_mrr_ema=0.243837, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.645110
Sat, 18 May 2019 13:15:41 unsupervised_train.py[line:355] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0000, max_total_steps: 100000000
Sat, 18 May 2019 13:16:11 unsupervised_train.py[line:353] INFO Iter: 0010, train_loss=17.518116, train_mrr=0.296808, train_mrr_ema=0.245686, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.121695
Sat, 18 May 2019 13:16:11 unsupervised_train.py[line:355] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0010, max_total_steps: 100000000
Sat, 18 May 2019 13:16:41 unsupervised_train.py[line:353] INFO Iter: 0020, train_loss=17.739954, train_mrr=0.296096, train_mrr_ema=0.247939, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.085067
Sat, 18 May 2019 13:16:41 unsupervised_train.py[line:355] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0020, max_total_steps: 100000000
Sat, 18 May 2019 13:17:15 unsupervised_train.py[line:353] INFO Iter: 0030, train_loss=17.046886, train_mrr=0.266572, train_mrr_ema=0.249935, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.155996
Sat, 18 May 2019 13:17:15 unsupervised_train.py[line:355] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0030, max_total_steps: 100000000
Sat, 18 May 2019 13:17:45 unsupervised_train.py[line:353] INFO Iter: 0040, train_loss=17.083702, train_mrr=0.267995, train_mrr_ema=0.253615, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.137398
Sat, 18 May 2019 13:17:45 unsupervised_train.py[line:355] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0040, max_total_steps: 100000000
Sat, 18 May 2019 13:18:22 unsupervised_train.py[line:353] INFO Iter: 0050, train_loss=16.256002, train_mrr=0.326079, train_mrr_ema=0.257604, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.236384
Sat, 18 May 2019 13:18:22 unsupervised_train.py[line:355] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0050, max_total_steps: 100000000
Sat, 18 May 2019 13:18:53 unsupervised_train.py[line:353] INFO Iter: 0060, train_loss=15.962955, train_mrr=0.278182, train_mrr_ema=0.260733, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.224684
Sat, 18 May 2019 13:18:53 unsupervised_train.py[line:355] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0060, max_total_steps: 100000000
Sat, 18 May 2019 13:19:25 unsupervised_train.py[line:353] INFO Iter: 0070, train_loss=16.002254, train_mrr=0.288942, train_mrr_ema=0.264283, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.214789
Sat, 18 May 2019 13:19:25 unsupervised_train.py[line:355] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0070, max_total_steps: 100000000
Sat, 18 May 2019 13:19:56 unsupervised_train.py[line:353] INFO Iter: 0080, train_loss=15.834500, train_mrr=0.309011, train_mrr_ema=0.267365, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.204852
Sat, 18 May 2019 13:19:56 unsupervised_train.py[line:355] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0080, max_total_steps: 100000000
Sat, 18 May 2019 13:20:28 unsupervised_train.py[line:353] INFO Iter: 0090, train_loss=15.371733, train_mrr=0.297302, train_mrr_ema=0.271217, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.197413
Sat, 18 May 2019 13:20:28 unsupervised_train.py[line:355] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0090, max_total_steps: 100000000
Sat, 18 May 2019 13:20:57 unsupervised_train.py[line:353] INFO Iter: 0100, train_loss=15.023630, train_mrr=0.327329, train_mrr_ema=0.275635, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.173692
Sat, 18 May 2019 13:20:57 unsupervised_train.py[line:355] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0100, max_total_steps: 100000000
Sat, 18 May 2019 13:21:26 unsupervised_train.py[line:353] INFO Iter: 0110, train_loss=15.163862, train_mrr=0.319073, train_mrr_ema=0.279989, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.148861
Sat, 18 May 2019 13:21:26 unsupervised_train.py[line:355] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0110, max_total_steps: 100000000
Sat, 18 May 2019 13:21:56 unsupervised_train.py[line:353] INFO Iter: 0120, train_loss=15.227827, train_mrr=0.311000, train_mrr_ema=0.283353, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.135250
Sat, 18 May 2019 13:21:56 unsupervised_train.py[line:355] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0120, max_total_steps: 100000000
Sat, 18 May 2019 13:22:28 unsupervised_train.py[line:353] INFO Iter: 0130, train_loss=15.169399, train_mrr=0.338767, train_mrr_ema=0.286833, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.139390
Sat, 18 May 2019 13:22:28 unsupervised_train.py[line:355] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0130, max_total_steps: 100000000
Sat, 18 May 2019 13:23:00 unsupervised_train.py[line:353] INFO Iter: 0140, train_loss=15.247789, train_mrr=0.281773, train_mrr_ema=0.290752, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.143817
Sat, 18 May 2019 13:23:00 unsupervised_train.py[line:355] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0140, max_total_steps: 100000000
Sat, 18 May 2019 13:23:32 unsupervised_train.py[line:353] INFO Iter: 0150, train_loss=15.048656, train_mrr=0.314890, train_mrr_ema=0.293423, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.144831
Sat, 18 May 2019 13:23:32 unsupervised_train.py[line:355] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0150, max_total_steps: 100000000
Sat, 18 May 2019 13:24:04 unsupervised_train.py[line:353] INFO Iter: 0160, train_loss=15.432567, train_mrr=0.308670, train_mrr_ema=0.296125, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.152240
Sat, 18 May 2019 13:24:04 unsupervised_train.py[line:355] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0160, max_total_steps: 100000000
Sat, 18 May 2019 13:24:37 unsupervised_train.py[line:353] INFO Iter: 0170, train_loss=14.781470, train_mrr=0.343460, train_mrr_ema=0.298240, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.156330
Sat, 18 May 2019 13:24:37 unsupervised_train.py[line:355] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0170, max_total_steps: 100000000
Sat, 18 May 2019 13:25:09 unsupervised_train.py[line:353] INFO Iter: 0180, train_loss=14.859788, train_mrr=0.348164, train_mrr_ema=0.300614, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.163707
Sat, 18 May 2019 13:25:09 unsupervised_train.py[line:355] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0180, max_total_steps: 100000000
Sat, 18 May 2019 13:25:49 unsupervised_train.py[line:353] INFO Iter: 0190, train_loss=14.514595, train_mrr=0.379552, train_mrr_ema=0.304119, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.206369
Sat, 18 May 2019 13:25:49 unsupervised_train.py[line:355] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0190, max_total_steps: 100000000
Sat, 18 May 2019 13:26:25 unsupervised_train.py[line:353] INFO Iter: 0200, train_loss=14.648949, train_mrr=0.367311, train_mrr_ema=0.306948, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.225993
Sat, 18 May 2019 13:26:25 unsupervised_train.py[line:355] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0200, max_total_steps: 100000000
Sat, 18 May 2019 13:27:02 unsupervised_train.py[line:353] INFO Iter: 0210, train_loss=14.932245, train_mrr=0.297271, train_mrr_ema=0.308972, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.248905
Sat, 18 May 2019 13:27:02 unsupervised_train.py[line:355] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0210, max_total_steps: 100000000
Sat, 18 May 2019 13:27:39 unsupervised_train.py[line:353] INFO Iter: 0220, train_loss=15.114847, train_mrr=0.348821, train_mrr_ema=0.311254, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.267360
Sat, 18 May 2019 13:27:39 unsupervised_train.py[line:355] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0220, max_total_steps: 100000000
Sat, 18 May 2019 13:28:06 unsupervised_train.py[line:376] INFO ######## Saving embedding data to file ##########
Sat, 18 May 2019 13:28:10 unsupervised_train.py[line:130] INFO Start saving embedding for succeed tasks
Sat, 18 May 2019 13:44:54 utils.py[line:43] INFO class map loaded
Sat, 18 May 2019 13:44:54 utils.py[line:59] INFO bad nodes removed
Sat, 18 May 2019 13:44:54 utils.py[line:78] INFO Normalized
Sat, 18 May 2019 13:44:55 utils.py[line:93] INFO data all loaded
Sat, 18 May 2019 13:44:55 unsupervised_train.py[line:441] INFO start training
Sat, 18 May 2019 13:44:55 unsupervised_train.py[line:190] INFO edge minibatch
Sat, 18 May 2019 13:44:55 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/10.Federated-Learning-with-DPASGD/sourcecode/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Sat, 18 May 2019 13:44:55 unsupervised_train.py[line:200] INFO choose model
Sat, 18 May 2019 13:44:55 deprecation.py[line:506] WARNING From /Users/chaoyanghe/Presentation/12.GraphNeuralNetwork/sourcecode/bipartite-graph-learning/GraphSage/graphsage/aggregators.py:46: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Sat, 18 May 2019 13:44:56 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/12.GraphNeuralNetwork/sourcecode/bipartite-graph-learning/GraphSage/graphsage/models.py:407: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
Sat, 18 May 2019 13:44:56 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/10.Federated-Learning-with-DPASGD/sourcecode/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Sat, 18 May 2019 13:44:57 unsupervised_train.py[line:312] INFO training epoch: 1
Sat, 18 May 2019 13:45:04 unsupervised_train.py[line:354] INFO Iter: 0000, train_loss=18.894554, train_mrr=0.237333, train_mrr_ema=0.237333, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=7.079776
Sat, 18 May 2019 13:45:04 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0000, max_total_steps: 100000000
Sat, 18 May 2019 13:45:37 unsupervised_train.py[line:354] INFO Iter: 0010, train_loss=17.713552, train_mrr=0.271403, train_mrr_ema=0.239798, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.659666
Sat, 18 May 2019 13:45:37 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0010, max_total_steps: 100000000
Sat, 18 May 2019 13:46:16 unsupervised_train.py[line:354] INFO Iter: 0020, train_loss=17.705988, train_mrr=0.299604, train_mrr_ema=0.242438, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.773992
Sat, 18 May 2019 13:46:16 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0020, max_total_steps: 100000000
Sat, 18 May 2019 13:46:58 unsupervised_train.py[line:354] INFO Iter: 0030, train_loss=16.834511, train_mrr=0.292326, train_mrr_ema=0.244897, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.906253
Sat, 18 May 2019 13:46:58 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0030, max_total_steps: 100000000
Sat, 18 May 2019 13:47:39 unsupervised_train.py[line:354] INFO Iter: 0040, train_loss=16.971514, train_mrr=0.310815, train_mrr_ema=0.249968, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.959349
Sat, 18 May 2019 13:47:39 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0040, max_total_steps: 100000000
Sat, 18 May 2019 13:48:20 unsupervised_train.py[line:354] INFO Iter: 0050, train_loss=16.179588, train_mrr=0.330187, train_mrr_ema=0.253982, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.986441
Sat, 18 May 2019 13:48:20 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0050, max_total_steps: 100000000
Sat, 18 May 2019 13:48:57 unsupervised_train.py[line:354] INFO Iter: 0060, train_loss=15.993050, train_mrr=0.270913, train_mrr_ema=0.257890, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.941323
Sat, 18 May 2019 13:48:57 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0060, max_total_steps: 100000000
Sat, 18 May 2019 13:49:35 unsupervised_train.py[line:354] INFO Iter: 0070, train_loss=16.126476, train_mrr=0.272653, train_mrr_ema=0.261504, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.922744
Sat, 18 May 2019 13:49:35 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0070, max_total_steps: 100000000
Sat, 18 May 2019 13:50:08 unsupervised_train.py[line:354] INFO Iter: 0080, train_loss=15.776451, train_mrr=0.289073, train_mrr_ema=0.264840, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.847225
Sat, 18 May 2019 13:50:08 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0080, max_total_steps: 100000000
Sat, 18 May 2019 13:50:47 unsupervised_train.py[line:354] INFO Iter: 0090, train_loss=15.300508, train_mrr=0.314669, train_mrr_ema=0.267916, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.850235
Sat, 18 May 2019 13:50:47 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0090, max_total_steps: 100000000
Sat, 18 May 2019 13:51:24 unsupervised_train.py[line:354] INFO Iter: 0100, train_loss=15.070523, train_mrr=0.309671, train_mrr_ema=0.271436, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.834704
Sat, 18 May 2019 13:51:24 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0100, max_total_steps: 100000000
Sat, 18 May 2019 13:52:04 unsupervised_train.py[line:354] INFO Iter: 0110, train_loss=15.210987, train_mrr=0.301413, train_mrr_ema=0.275346, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.846116
Sat, 18 May 2019 13:52:04 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0110, max_total_steps: 100000000
Sat, 18 May 2019 13:52:47 unsupervised_train.py[line:354] INFO Iter: 0120, train_loss=15.259116, train_mrr=0.299937, train_mrr_ema=0.278644, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.883869
Sat, 18 May 2019 13:52:47 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0120, max_total_steps: 100000000
Sat, 18 May 2019 13:53:25 unsupervised_train.py[line:354] INFO Iter: 0130, train_loss=15.139942, train_mrr=0.287707, train_mrr_ema=0.282436, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.879614
Sat, 18 May 2019 13:53:25 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0130, max_total_steps: 100000000
Sat, 18 May 2019 13:54:03 unsupervised_train.py[line:354] INFO Iter: 0140, train_loss=15.239860, train_mrr=0.301076, train_mrr_ema=0.286212, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.871780
Sat, 18 May 2019 13:54:03 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0140, max_total_steps: 100000000
Sat, 18 May 2019 13:54:55 unsupervised_train.py[line:354] INFO Iter: 0150, train_loss=15.047591, train_mrr=0.320727, train_mrr_ema=0.288786, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.961293
Sat, 18 May 2019 13:54:55 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0150, max_total_steps: 100000000
Sat, 18 May 2019 13:55:44 unsupervised_train.py[line:354] INFO Iter: 0160, train_loss=15.366654, train_mrr=0.293096, train_mrr_ema=0.291438, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.018039
Sat, 18 May 2019 13:55:44 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0160, max_total_steps: 100000000
Sat, 18 May 2019 13:56:33 unsupervised_train.py[line:354] INFO Iter: 0170, train_loss=14.769646, train_mrr=0.345775, train_mrr_ema=0.294506, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.070839
Sat, 18 May 2019 13:56:33 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0170, max_total_steps: 100000000
Sat, 18 May 2019 13:57:09 unsupervised_train.py[line:354] INFO Iter: 0180, train_loss=14.803747, train_mrr=0.347869, train_mrr_ema=0.297397, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.041731
Sat, 18 May 2019 13:57:09 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0180, max_total_steps: 100000000
Sat, 18 May 2019 13:57:49 unsupervised_train.py[line:354] INFO Iter: 0190, train_loss=14.693004, train_mrr=0.361687, train_mrr_ema=0.300107, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.041418
Sat, 18 May 2019 13:57:49 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0190, max_total_steps: 100000000
Sat, 18 May 2019 13:58:25 unsupervised_train.py[line:354] INFO Iter: 0200, train_loss=14.713474, train_mrr=0.332799, train_mrr_ema=0.304107, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.017494
Sat, 18 May 2019 13:58:25 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0200, max_total_steps: 100000000
Sat, 18 May 2019 13:58:57 unsupervised_train.py[line:354] INFO Iter: 0210, train_loss=14.906925, train_mrr=0.329047, train_mrr_ema=0.307008, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.981123
Sat, 18 May 2019 13:58:57 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0210, max_total_steps: 100000000
Sat, 18 May 2019 13:59:30 unsupervised_train.py[line:354] INFO Iter: 0220, train_loss=15.065188, train_mrr=0.326657, train_mrr_ema=0.309002, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.949839
Sat, 18 May 2019 13:59:30 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0220, max_total_steps: 100000000
Sat, 18 May 2019 13:59:58 unsupervised_train.py[line:377] INFO ######## Saving embedding data to file ##########
Sat, 18 May 2019 14:00:04 unsupervised_train.py[line:131] INFO Start saving embedding for succeed tasks
Sat, 18 May 2019 14:00:04 unsupervised_train.py[line:149] INFO Number of nodes in set U: 734
Sat, 18 May 2019 14:13:39 utils.py[line:43] INFO class map loaded
Sat, 18 May 2019 14:13:39 utils.py[line:59] INFO bad nodes removed
Sat, 18 May 2019 14:13:40 utils.py[line:78] INFO Normalized
Sat, 18 May 2019 14:13:40 utils.py[line:93] INFO data all loaded
Sat, 18 May 2019 14:13:40 unsupervised_train.py[line:441] INFO start training
Sat, 18 May 2019 14:13:40 unsupervised_train.py[line:190] INFO edge minibatch
Sat, 18 May 2019 14:13:41 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/10.Federated-Learning-with-DPASGD/sourcecode/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Sat, 18 May 2019 14:13:41 unsupervised_train.py[line:200] INFO choose model
Sat, 18 May 2019 14:13:41 deprecation.py[line:506] WARNING From /Users/chaoyanghe/Presentation/12.GraphNeuralNetwork/sourcecode/bipartite-graph-learning/GraphSage/graphsage/aggregators.py:46: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Sat, 18 May 2019 14:13:41 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/12.GraphNeuralNetwork/sourcecode/bipartite-graph-learning/GraphSage/graphsage/models.py:407: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
Sat, 18 May 2019 14:13:41 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/10.Federated-Learning-with-DPASGD/sourcecode/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Sat, 18 May 2019 14:13:42 unsupervised_train.py[line:312] INFO training epoch: 1
Sat, 18 May 2019 14:13:47 unsupervised_train.py[line:354] INFO Iter: 0000, train_loss=18.928637, train_mrr=0.268781, train_mrr_ema=0.268781, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=5.259490
Sat, 18 May 2019 14:13:47 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0000, max_total_steps: 100000000
Sat, 18 May 2019 14:14:21 unsupervised_train.py[line:354] INFO Iter: 0010, train_loss=17.672108, train_mrr=0.304825, train_mrr_ema=0.267634, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.529886
Sat, 18 May 2019 14:14:21 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0010, max_total_steps: 100000000
Sat, 18 May 2019 14:15:01 unsupervised_train.py[line:354] INFO Iter: 0020, train_loss=17.681154, train_mrr=0.309941, train_mrr_ema=0.268133, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.746284
Sat, 18 May 2019 14:15:01 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0020, max_total_steps: 100000000
Sat, 18 May 2019 14:15:33 unsupervised_train.py[line:354] INFO Iter: 0030, train_loss=16.985207, train_mrr=0.276313, train_mrr_ema=0.268788, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.587120
Sat, 18 May 2019 14:15:33 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0030, max_total_steps: 100000000
Sat, 18 May 2019 14:16:13 unsupervised_train.py[line:354] INFO Iter: 0040, train_loss=17.106197, train_mrr=0.274409, train_mrr_ema=0.270163, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.686928
Sat, 18 May 2019 14:16:13 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0040, max_total_steps: 100000000
Sat, 18 May 2019 14:17:03 unsupervised_train.py[line:354] INFO Iter: 0050, train_loss=16.204933, train_mrr=0.297040, train_mrr_ema=0.272127, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.945827
Sat, 18 May 2019 14:17:03 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0050, max_total_steps: 100000000
Sat, 18 May 2019 14:17:38 unsupervised_train.py[line:354] INFO Iter: 0060, train_loss=16.069963, train_mrr=0.260884, train_mrr_ema=0.274150, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.859469
Sat, 18 May 2019 14:17:38 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0060, max_total_steps: 100000000
Sat, 18 May 2019 14:18:08 unsupervised_train.py[line:354] INFO Iter: 0070, train_loss=16.097805, train_mrr=0.290642, train_mrr_ema=0.276902, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.748180
Sat, 18 May 2019 14:18:08 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0070, max_total_steps: 100000000
Sat, 18 May 2019 14:18:43 unsupervised_train.py[line:354] INFO Iter: 0080, train_loss=15.717946, train_mrr=0.318647, train_mrr_ema=0.278583, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.717009
Sat, 18 May 2019 14:18:43 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0080, max_total_steps: 100000000
Sat, 18 May 2019 14:19:18 unsupervised_train.py[line:354] INFO Iter: 0090, train_loss=15.423696, train_mrr=0.303231, train_mrr_ema=0.280763, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.691811
Sat, 18 May 2019 14:19:18 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0090, max_total_steps: 100000000
Sat, 18 May 2019 14:19:56 unsupervised_train.py[line:354] INFO Iter: 0100, train_loss=15.016929, train_mrr=0.326188, train_mrr_ema=0.283753, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.704071
Sat, 18 May 2019 14:19:56 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0100, max_total_steps: 100000000
Sat, 18 May 2019 14:20:31 unsupervised_train.py[line:354] INFO Iter: 0110, train_loss=15.183565, train_mrr=0.349204, train_mrr_ema=0.286474, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.684624
Sat, 18 May 2019 14:20:31 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0110, max_total_steps: 100000000
Sat, 18 May 2019 14:21:02 unsupervised_train.py[line:354] INFO Iter: 0120, train_loss=15.173934, train_mrr=0.295225, train_mrr_ema=0.289093, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.633982
Sat, 18 May 2019 14:21:02 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0120, max_total_steps: 100000000
Sat, 18 May 2019 14:21:33 unsupervised_train.py[line:354] INFO Iter: 0130, train_loss=15.120960, train_mrr=0.298049, train_mrr_ema=0.291401, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.592415
Sat, 18 May 2019 14:21:33 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0130, max_total_steps: 100000000
Sat, 18 May 2019 14:22:10 unsupervised_train.py[line:354] INFO Iter: 0140, train_loss=15.290978, train_mrr=0.289025, train_mrr_ema=0.294303, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.600580
Sat, 18 May 2019 14:22:10 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0140, max_total_steps: 100000000
Sat, 18 May 2019 14:22:50 unsupervised_train.py[line:354] INFO Iter: 0150, train_loss=15.127673, train_mrr=0.303750, train_mrr_ema=0.296030, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.629090
Sat, 18 May 2019 14:22:50 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0150, max_total_steps: 100000000
Sat, 18 May 2019 14:23:27 unsupervised_train.py[line:354] INFO Iter: 0160, train_loss=15.380507, train_mrr=0.321699, train_mrr_ema=0.298421, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.633188
Sat, 18 May 2019 14:23:27 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0160, max_total_steps: 100000000
Sat, 18 May 2019 14:23:58 unsupervised_train.py[line:354] INFO Iter: 0170, train_loss=14.817734, train_mrr=0.309148, train_mrr_ema=0.300024, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.601525
Sat, 18 May 2019 14:23:58 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0170, max_total_steps: 100000000
Sat, 18 May 2019 14:24:33 unsupervised_train.py[line:354] INFO Iter: 0180, train_loss=14.845940, train_mrr=0.318636, train_mrr_ema=0.302284, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.593586
Sat, 18 May 2019 14:24:33 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0180, max_total_steps: 100000000
Sat, 18 May 2019 14:25:04 unsupervised_train.py[line:354] INFO Iter: 0190, train_loss=14.653142, train_mrr=0.377898, train_mrr_ema=0.304852, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.567761
Sat, 18 May 2019 14:25:04 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0190, max_total_steps: 100000000
Sat, 18 May 2019 14:25:35 unsupervised_train.py[line:354] INFO Iter: 0200, train_loss=14.818074, train_mrr=0.358068, train_mrr_ema=0.308524, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.546935
Sat, 18 May 2019 14:25:35 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0200, max_total_steps: 100000000
Sat, 18 May 2019 14:26:10 unsupervised_train.py[line:354] INFO Iter: 0210, train_loss=14.891071, train_mrr=0.338924, train_mrr_ema=0.310025, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.542550
Sat, 18 May 2019 14:26:10 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0210, max_total_steps: 100000000
Sat, 18 May 2019 14:26:42 unsupervised_train.py[line:354] INFO Iter: 0220, train_loss=15.168247, train_mrr=0.346407, train_mrr_ema=0.312839, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.527121
Sat, 18 May 2019 14:26:42 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0220, max_total_steps: 100000000
Sat, 18 May 2019 14:27:07 unsupervised_train.py[line:377] INFO ######## Saving embedding data to file ##########
Sat, 18 May 2019 14:27:10 unsupervised_train.py[line:131] INFO Start saving embedding for succeed tasks
Sat, 18 May 2019 14:27:10 unsupervised_train.py[line:149] INFO Number of nodes in set U: 734
Sat, 18 May 2019 16:58:10 utils.py[line:43] INFO class map loaded
Sat, 18 May 2019 16:58:10 utils.py[line:59] INFO bad nodes removed
Sat, 18 May 2019 16:58:10 utils.py[line:78] INFO Normalized
Sat, 18 May 2019 16:58:11 utils.py[line:93] INFO data all loaded
Sat, 18 May 2019 16:58:11 unsupervised_train.py[line:441] INFO start training
Sat, 18 May 2019 16:58:11 unsupervised_train.py[line:190] INFO edge minibatch
Sat, 18 May 2019 16:58:11 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/10.Federated-Learning-with-DPASGD/sourcecode/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Sat, 18 May 2019 16:58:11 unsupervised_train.py[line:200] INFO choose model
Sat, 18 May 2019 16:58:12 deprecation.py[line:506] WARNING From /Users/chaoyanghe/Presentation/12.GraphNeuralNetwork/sourcecode/bipartite-graph-learning/GraphSage/graphsage/aggregators.py:46: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Sat, 18 May 2019 16:58:12 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/12.GraphNeuralNetwork/sourcecode/bipartite-graph-learning/GraphSage/graphsage/models.py:407: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
Sat, 18 May 2019 16:58:12 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/10.Federated-Learning-with-DPASGD/sourcecode/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Sat, 18 May 2019 16:58:13 unsupervised_train.py[line:312] INFO training epoch: 1
Sat, 18 May 2019 16:58:20 unsupervised_train.py[line:354] INFO Iter: 0000, train_loss=18.762217, train_mrr=0.241739, train_mrr_ema=0.241739, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=6.607040
Sat, 18 May 2019 16:58:20 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0000, max_total_steps: 100000000
Sat, 18 May 2019 16:58:58 unsupervised_train.py[line:354] INFO Iter: 0010, train_loss=17.712744, train_mrr=0.282499, train_mrr_ema=0.243523, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.072237
Sat, 18 May 2019 16:58:58 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0010, max_total_steps: 100000000
Sat, 18 May 2019 16:59:31 unsupervised_train.py[line:354] INFO Iter: 0020, train_loss=17.638630, train_mrr=0.293678, train_mrr_ema=0.247258, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.727610
Sat, 18 May 2019 16:59:31 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0020, max_total_steps: 100000000
Sat, 18 May 2019 17:00:03 unsupervised_train.py[line:354] INFO Iter: 0030, train_loss=17.138588, train_mrr=0.294281, train_mrr_ema=0.249169, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.545081
Sat, 18 May 2019 17:00:03 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0030, max_total_steps: 100000000
Sat, 18 May 2019 17:00:54 unsupervised_train.py[line:354] INFO Iter: 0040, train_loss=17.145462, train_mrr=0.307280, train_mrr_ema=0.252783, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.915766
Sat, 18 May 2019 17:00:54 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0040, max_total_steps: 100000000
Sat, 18 May 2019 17:01:27 unsupervised_train.py[line:354] INFO Iter: 0050, train_loss=16.159372, train_mrr=0.341706, train_mrr_ema=0.256676, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.803607
Sat, 18 May 2019 17:01:27 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0050, max_total_steps: 100000000
Sat, 18 May 2019 17:01:58 unsupervised_train.py[line:354] INFO Iter: 0060, train_loss=15.995302, train_mrr=0.292703, train_mrr_ema=0.261013, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.689477
Sat, 18 May 2019 17:01:58 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0060, max_total_steps: 100000000
Sat, 18 May 2019 17:02:28 unsupervised_train.py[line:354] INFO Iter: 0070, train_loss=16.029327, train_mrr=0.276952, train_mrr_ema=0.264520, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.585283
Sat, 18 May 2019 17:02:28 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0070, max_total_steps: 100000000
Sat, 18 May 2019 17:02:58 unsupervised_train.py[line:354] INFO Iter: 0080, train_loss=15.839238, train_mrr=0.311394, train_mrr_ema=0.268471, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.522292
Sat, 18 May 2019 17:02:58 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0080, max_total_steps: 100000000
Sat, 18 May 2019 17:03:30 unsupervised_train.py[line:354] INFO Iter: 0090, train_loss=15.374156, train_mrr=0.330054, train_mrr_ema=0.273099, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.479921
Sat, 18 May 2019 17:03:30 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0090, max_total_steps: 100000000
Sat, 18 May 2019 17:04:00 unsupervised_train.py[line:354] INFO Iter: 0100, train_loss=15.047021, train_mrr=0.303865, train_mrr_ema=0.276138, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.430639
Sat, 18 May 2019 17:04:00 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0100, max_total_steps: 100000000
Sat, 18 May 2019 17:04:32 unsupervised_train.py[line:354] INFO Iter: 0110, train_loss=15.186220, train_mrr=0.321867, train_mrr_ema=0.279430, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.409688
Sat, 18 May 2019 17:04:32 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0110, max_total_steps: 100000000
Sat, 18 May 2019 17:05:06 unsupervised_train.py[line:354] INFO Iter: 0120, train_loss=15.161578, train_mrr=0.322173, train_mrr_ema=0.283031, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.414492
Sat, 18 May 2019 17:05:06 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0120, max_total_steps: 100000000
Sat, 18 May 2019 17:05:53 unsupervised_train.py[line:354] INFO Iter: 0130, train_loss=15.211283, train_mrr=0.284649, train_mrr_ema=0.286035, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.507889
Sat, 18 May 2019 17:05:53 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0130, max_total_steps: 100000000
Sat, 18 May 2019 17:06:42 unsupervised_train.py[line:354] INFO Iter: 0140, train_loss=15.272691, train_mrr=0.349765, train_mrr_ema=0.290461, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.610162
Sat, 18 May 2019 17:06:42 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0140, max_total_steps: 100000000
Sat, 18 May 2019 17:07:34 unsupervised_train.py[line:354] INFO Iter: 0150, train_loss=14.938892, train_mrr=0.342326, train_mrr_ema=0.293222, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.714453
Sat, 18 May 2019 17:07:34 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0150, max_total_steps: 100000000
Sat, 18 May 2019 17:08:19 unsupervised_train.py[line:354] INFO Iter: 0160, train_loss=15.323959, train_mrr=0.313266, train_mrr_ema=0.295845, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.765176
Sat, 18 May 2019 17:08:19 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0160, max_total_steps: 100000000
Sat, 18 May 2019 17:08:52 unsupervised_train.py[line:354] INFO Iter: 0170, train_loss=14.873294, train_mrr=0.329772, train_mrr_ema=0.298145, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.738009
Sat, 18 May 2019 17:08:52 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0170, max_total_steps: 100000000
Sat, 18 May 2019 17:09:30 unsupervised_train.py[line:354] INFO Iter: 0180, train_loss=14.974285, train_mrr=0.292424, train_mrr_ema=0.300615, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.740344
Sat, 18 May 2019 17:09:30 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0180, max_total_steps: 100000000
Sat, 18 May 2019 17:10:09 unsupervised_train.py[line:354] INFO Iter: 0190, train_loss=14.561989, train_mrr=0.366844, train_mrr_ema=0.303013, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.745986
Sat, 18 May 2019 17:10:09 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0190, max_total_steps: 100000000
Sat, 18 May 2019 17:10:48 unsupervised_train.py[line:354] INFO Iter: 0200, train_loss=14.804757, train_mrr=0.336949, train_mrr_ema=0.306366, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.756119
Sat, 18 May 2019 17:10:48 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0200, max_total_steps: 100000000
Sat, 18 May 2019 17:11:27 unsupervised_train.py[line:354] INFO Iter: 0210, train_loss=14.891695, train_mrr=0.322292, train_mrr_ema=0.309103, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.759969
Sat, 18 May 2019 17:11:27 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0210, max_total_steps: 100000000
Sat, 18 May 2019 17:12:07 unsupervised_train.py[line:354] INFO Iter: 0220, train_loss=15.020719, train_mrr=0.372863, train_mrr_ema=0.311608, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.772788
Sat, 18 May 2019 17:12:07 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0220, max_total_steps: 100000000
Sat, 18 May 2019 17:12:48 unsupervised_train.py[line:377] INFO ######## Saving embedding data to file ##########
Sat, 18 May 2019 17:12:52 unsupervised_train.py[line:131] INFO Start saving embedding for succeed tasks
Sat, 18 May 2019 17:12:52 unsupervised_train.py[line:149] INFO Number of nodes in set U: 734
Sat, 18 May 2019 17:15:04 utils.py[line:43] INFO class map loaded
Sat, 18 May 2019 17:15:04 utils.py[line:59] INFO bad nodes removed
Sat, 18 May 2019 17:15:05 utils.py[line:78] INFO Normalized
Sat, 18 May 2019 17:15:05 utils.py[line:93] INFO data all loaded
Sat, 18 May 2019 17:15:05 unsupervised_train.py[line:441] INFO start training
Sat, 18 May 2019 17:15:05 unsupervised_train.py[line:190] INFO edge minibatch
Sat, 18 May 2019 17:15:06 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/10.Federated-Learning-with-DPASGD/sourcecode/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Sat, 18 May 2019 17:15:06 unsupervised_train.py[line:200] INFO choose model
Sat, 18 May 2019 17:15:06 deprecation.py[line:506] WARNING From /Users/chaoyanghe/Presentation/12.GraphNeuralNetwork/sourcecode/bipartite-graph-learning/GraphSage/graphsage/aggregators.py:46: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Sat, 18 May 2019 17:15:06 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/12.GraphNeuralNetwork/sourcecode/bipartite-graph-learning/GraphSage/graphsage/models.py:407: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
Sat, 18 May 2019 17:15:07 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/10.Federated-Learning-with-DPASGD/sourcecode/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Sat, 18 May 2019 17:15:08 unsupervised_train.py[line:312] INFO training epoch: 1
Sat, 18 May 2019 17:15:13 unsupervised_train.py[line:354] INFO Iter: 0000, train_loss=18.925703, train_mrr=0.285915, train_mrr_ema=0.285915, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=5.167347
Sat, 18 May 2019 17:15:13 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0000, max_total_steps: 100000000
Sat, 18 May 2019 17:15:50 unsupervised_train.py[line:354] INFO Iter: 0010, train_loss=17.718452, train_mrr=0.303135, train_mrr_ema=0.284503, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.838431
Sat, 18 May 2019 17:15:50 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0010, max_total_steps: 100000000
Sat, 18 May 2019 17:15:59 utils.py[line:43] INFO class map loaded
Sat, 18 May 2019 17:15:59 utils.py[line:59] INFO bad nodes removed
Sat, 18 May 2019 17:15:59 utils.py[line:78] INFO Normalized
Sat, 18 May 2019 17:16:00 utils.py[line:93] INFO data all loaded
Sat, 18 May 2019 17:16:00 unsupervised_train.py[line:441] INFO start training
Sat, 18 May 2019 17:16:00 unsupervised_train.py[line:190] INFO edge minibatch
Sat, 18 May 2019 17:16:00 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/10.Federated-Learning-with-DPASGD/sourcecode/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Sat, 18 May 2019 17:16:00 unsupervised_train.py[line:200] INFO choose model
Sat, 18 May 2019 17:16:00 deprecation.py[line:506] WARNING From /Users/chaoyanghe/Presentation/12.GraphNeuralNetwork/sourcecode/bipartite-graph-learning/GraphSage/graphsage/aggregators.py:46: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Sat, 18 May 2019 17:16:01 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/12.GraphNeuralNetwork/sourcecode/bipartite-graph-learning/GraphSage/graphsage/models.py:407: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
Sat, 18 May 2019 17:16:01 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/10.Federated-Learning-with-DPASGD/sourcecode/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Sat, 18 May 2019 17:16:02 unsupervised_train.py[line:312] INFO training epoch: 1
Sat, 18 May 2019 17:16:06 unsupervised_train.py[line:354] INFO Iter: 0000, train_loss=18.899809, train_mrr=0.251318, train_mrr_ema=0.251318, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.250122
Sat, 18 May 2019 17:16:06 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0000, max_total_steps: 100000000
Sat, 18 May 2019 17:18:37 utils.py[line:43] INFO class map loaded
Sat, 18 May 2019 17:18:37 utils.py[line:59] INFO bad nodes removed
Sat, 18 May 2019 17:18:37 utils.py[line:78] INFO Normalized
Sat, 18 May 2019 17:18:38 utils.py[line:93] INFO data all loaded
Sat, 18 May 2019 17:18:38 unsupervised_train.py[line:441] INFO start training
Sat, 18 May 2019 17:18:38 unsupervised_train.py[line:190] INFO edge minibatch
Sat, 18 May 2019 17:18:39 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/10.Federated-Learning-with-DPASGD/sourcecode/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Sat, 18 May 2019 17:18:39 unsupervised_train.py[line:200] INFO choose model
Sat, 18 May 2019 17:18:39 deprecation.py[line:506] WARNING From /Users/chaoyanghe/Presentation/12.GraphNeuralNetwork/sourcecode/bipartite-graph-learning/GraphSage/graphsage/aggregators.py:46: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Sat, 18 May 2019 17:18:39 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/12.GraphNeuralNetwork/sourcecode/bipartite-graph-learning/GraphSage/graphsage/models.py:407: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
Sat, 18 May 2019 17:18:39 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/10.Federated-Learning-with-DPASGD/sourcecode/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Sat, 18 May 2019 17:18:40 unsupervised_train.py[line:312] INFO training epoch: 1
Sat, 18 May 2019 17:18:44 unsupervised_train.py[line:354] INFO Iter: 0000, train_loss=18.953279, train_mrr=0.258721, train_mrr_ema=0.258721, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.906264
Sat, 18 May 2019 17:18:44 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0000, max_total_steps: 100000000
Sat, 18 May 2019 17:19:20 unsupervised_train.py[line:354] INFO Iter: 0010, train_loss=17.535948, train_mrr=0.301621, train_mrr_ema=0.259483, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.560398
Sat, 18 May 2019 17:19:20 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0010, max_total_steps: 100000000
Sat, 18 May 2019 17:20:03 unsupervised_train.py[line:354] INFO Iter: 0020, train_loss=17.572443, train_mrr=0.252573, train_mrr_ema=0.260154, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.914544
Sat, 18 May 2019 17:20:03 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0020, max_total_steps: 100000000
Sat, 18 May 2019 17:20:43 unsupervised_train.py[line:354] INFO Iter: 0030, train_loss=16.840784, train_mrr=0.303639, train_mrr_ema=0.260837, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.960052
Sat, 18 May 2019 17:20:43 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0030, max_total_steps: 100000000
Sat, 18 May 2019 17:21:27 unsupervised_train.py[line:354] INFO Iter: 0040, train_loss=16.980227, train_mrr=0.272422, train_mrr_ema=0.263024, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.057000
Sat, 18 May 2019 17:21:27 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0040, max_total_steps: 100000000
Sat, 18 May 2019 17:22:10 unsupervised_train.py[line:354] INFO Iter: 0050, train_loss=16.075504, train_mrr=0.317819, train_mrr_ema=0.266357, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.117723
Sat, 18 May 2019 17:22:10 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0050, max_total_steps: 100000000
Sat, 18 May 2019 17:23:02 unsupervised_train.py[line:354] INFO Iter: 0060, train_loss=16.031519, train_mrr=0.292884, train_mrr_ema=0.269006, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.285328
Sat, 18 May 2019 17:23:02 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0060, max_total_steps: 100000000
Sat, 18 May 2019 17:23:54 unsupervised_train.py[line:354] INFO Iter: 0070, train_loss=15.987708, train_mrr=0.278899, train_mrr_ema=0.271639, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.420430
Sat, 18 May 2019 17:23:54 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0070, max_total_steps: 100000000
Sat, 18 May 2019 17:24:28 unsupervised_train.py[line:354] INFO Iter: 0080, train_loss=15.748439, train_mrr=0.308498, train_mrr_ema=0.274026, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.289771
Sat, 18 May 2019 17:24:28 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0080, max_total_steps: 100000000
Sat, 18 May 2019 17:24:59 unsupervised_train.py[line:354] INFO Iter: 0090, train_loss=15.394870, train_mrr=0.309272, train_mrr_ema=0.276072, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.162110
Sat, 18 May 2019 17:24:59 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0090, max_total_steps: 100000000
Sat, 18 May 2019 17:25:28 unsupervised_train.py[line:354] INFO Iter: 0100, train_loss=15.022277, train_mrr=0.326835, train_mrr_ema=0.279594, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.032648
Sat, 18 May 2019 17:25:28 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0100, max_total_steps: 100000000
Sat, 18 May 2019 17:25:57 unsupervised_train.py[line:354] INFO Iter: 0110, train_loss=15.185404, train_mrr=0.319865, train_mrr_ema=0.283769, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.931445
Sat, 18 May 2019 17:25:57 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0110, max_total_steps: 100000000
Sat, 18 May 2019 17:26:26 unsupervised_train.py[line:354] INFO Iter: 0120, train_loss=15.200827, train_mrr=0.314649, train_mrr_ema=0.286970, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.848077
Sat, 18 May 2019 17:26:26 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0120, max_total_steps: 100000000
Sat, 18 May 2019 17:26:56 unsupervised_train.py[line:354] INFO Iter: 0130, train_loss=15.125493, train_mrr=0.317027, train_mrr_ema=0.288822, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.778560
Sat, 18 May 2019 17:26:56 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0130, max_total_steps: 100000000
Sat, 18 May 2019 17:27:36 unsupervised_train.py[line:354] INFO Iter: 0140, train_loss=15.229485, train_mrr=0.300203, train_mrr_ema=0.292670, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.799208
Sat, 18 May 2019 17:27:36 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0140, max_total_steps: 100000000
Sat, 18 May 2019 17:28:11 unsupervised_train.py[line:354] INFO Iter: 0150, train_loss=15.040224, train_mrr=0.317955, train_mrr_ema=0.295359, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.779872
Sat, 18 May 2019 17:28:11 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0150, max_total_steps: 100000000
Sat, 18 May 2019 17:28:43 unsupervised_train.py[line:354] INFO Iter: 0160, train_loss=15.335536, train_mrr=0.299110, train_mrr_ema=0.297220, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.741405
Sat, 18 May 2019 17:28:43 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0160, max_total_steps: 100000000
Sat, 18 May 2019 17:29:22 unsupervised_train.py[line:354] INFO Iter: 0170, train_loss=14.907091, train_mrr=0.328178, train_mrr_ema=0.299676, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.748584
Sat, 18 May 2019 17:29:22 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0170, max_total_steps: 100000000
Sat, 18 May 2019 17:29:57 unsupervised_train.py[line:354] INFO Iter: 0180, train_loss=14.911413, train_mrr=0.331145, train_mrr_ema=0.301551, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.734474
Sat, 18 May 2019 17:29:57 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0180, max_total_steps: 100000000
Sat, 18 May 2019 17:30:28 unsupervised_train.py[line:354] INFO Iter: 0190, train_loss=14.459930, train_mrr=0.402591, train_mrr_ema=0.304734, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.706223
Sat, 18 May 2019 17:30:28 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0190, max_total_steps: 100000000
Sat, 18 May 2019 17:31:04 unsupervised_train.py[line:354] INFO Iter: 0200, train_loss=14.837898, train_mrr=0.327554, train_mrr_ema=0.308107, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.700603
Sat, 18 May 2019 17:31:04 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0200, max_total_steps: 100000000
Sat, 18 May 2019 17:31:35 unsupervised_train.py[line:354] INFO Iter: 0210, train_loss=14.894256, train_mrr=0.342653, train_mrr_ema=0.311037, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.671922
Sat, 18 May 2019 17:31:35 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0210, max_total_steps: 100000000
Sat, 18 May 2019 17:32:09 unsupervised_train.py[line:354] INFO Iter: 0220, train_loss=15.008892, train_mrr=0.367553, train_mrr_ema=0.313984, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.659904
Sat, 18 May 2019 17:32:09 unsupervised_train.py[line:356] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0220, max_total_steps: 100000000
Sat, 18 May 2019 17:32:34 unsupervised_train.py[line:377] INFO ######## Saving embedding data to file ##########
Sat, 18 May 2019 17:32:37 unsupervised_train.py[line:131] INFO Start saving embedding for succeed tasks
Sat, 18 May 2019 17:32:37 unsupervised_train.py[line:149] INFO Number of nodes in set U: 734
Sat, 18 May 2019 17:44:41 utils.py[line:43] INFO class map loaded
Sat, 18 May 2019 17:44:41 utils.py[line:59] INFO bad nodes removed
Sat, 18 May 2019 17:44:41 utils.py[line:78] INFO Normalized
Sat, 18 May 2019 17:44:41 utils.py[line:93] INFO data all loaded
Sat, 18 May 2019 17:44:41 unsupervised_train.py[line:443] INFO start training
Sat, 18 May 2019 17:44:41 unsupervised_train.py[line:192] INFO edge minibatch
Sat, 18 May 2019 17:44:42 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/10.Federated-Learning-with-DPASGD/sourcecode/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Sat, 18 May 2019 17:44:42 unsupervised_train.py[line:202] INFO choose model
Sat, 18 May 2019 17:44:42 deprecation.py[line:506] WARNING From /Users/chaoyanghe/Presentation/12.GraphNeuralNetwork/sourcecode/bipartite-graph-learning/GraphSage/graphsage/aggregators.py:46: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Sat, 18 May 2019 17:44:42 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/12.GraphNeuralNetwork/sourcecode/bipartite-graph-learning/GraphSage/graphsage/models.py:407: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
Sat, 18 May 2019 17:44:42 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/10.Federated-Learning-with-DPASGD/sourcecode/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Sat, 18 May 2019 17:44:43 unsupervised_train.py[line:314] INFO training epoch: 1
Sat, 18 May 2019 17:44:48 unsupervised_train.py[line:356] INFO Iter: 0000, train_loss=18.976265, train_mrr=0.246600, train_mrr_ema=0.246600, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=5.202259
Sat, 18 May 2019 17:44:48 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0000, max_total_steps: 100000000
Sat, 18 May 2019 17:45:18 unsupervised_train.py[line:356] INFO Iter: 0010, train_loss=17.625990, train_mrr=0.281659, train_mrr_ema=0.248754, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.201688
Sat, 18 May 2019 17:45:18 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0010, max_total_steps: 100000000
Sat, 18 May 2019 17:45:49 unsupervised_train.py[line:356] INFO Iter: 0020, train_loss=17.881735, train_mrr=0.292921, train_mrr_ema=0.250254, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.138130
Sat, 18 May 2019 17:45:49 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0020, max_total_steps: 100000000
Sat, 18 May 2019 17:46:18 unsupervised_train.py[line:356] INFO Iter: 0030, train_loss=17.128273, train_mrr=0.290740, train_mrr_ema=0.252457, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.071611
Sat, 18 May 2019 17:46:18 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0030, max_total_steps: 100000000
Sat, 18 May 2019 17:46:49 unsupervised_train.py[line:356] INFO Iter: 0040, train_loss=17.100481, train_mrr=0.285689, train_mrr_ema=0.256268, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.078055
Sat, 18 May 2019 17:46:49 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0040, max_total_steps: 100000000
Sat, 18 May 2019 17:47:20 unsupervised_train.py[line:356] INFO Iter: 0050, train_loss=16.138098, train_mrr=0.303576, train_mrr_ema=0.258873, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.072948
Sat, 18 May 2019 17:47:20 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0050, max_total_steps: 100000000
Sat, 18 May 2019 17:47:50 unsupervised_train.py[line:356] INFO Iter: 0060, train_loss=16.014267, train_mrr=0.279611, train_mrr_ema=0.262464, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.060246
Sat, 18 May 2019 17:47:50 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0060, max_total_steps: 100000000
Sat, 18 May 2019 17:48:20 unsupervised_train.py[line:356] INFO Iter: 0070, train_loss=16.111609, train_mrr=0.270001, train_mrr_ema=0.265808, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.049164
Sat, 18 May 2019 17:48:20 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0070, max_total_steps: 100000000
Sat, 18 May 2019 17:48:55 unsupervised_train.py[line:356] INFO Iter: 0080, train_loss=15.742161, train_mrr=0.304354, train_mrr_ema=0.268697, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.112582
Sat, 18 May 2019 17:48:55 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0080, max_total_steps: 100000000
Sat, 18 May 2019 17:49:35 unsupervised_train.py[line:356] INFO Iter: 0090, train_loss=15.324514, train_mrr=0.321064, train_mrr_ema=0.272499, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.204446
Sat, 18 May 2019 17:49:35 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0090, max_total_steps: 100000000
Sat, 18 May 2019 17:50:09 unsupervised_train.py[line:356] INFO Iter: 0100, train_loss=14.991968, train_mrr=0.314474, train_mrr_ema=0.275828, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.225029
Sat, 18 May 2019 17:50:09 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0100, max_total_steps: 100000000
Sat, 18 May 2019 17:50:44 unsupervised_train.py[line:356] INFO Iter: 0110, train_loss=15.176843, train_mrr=0.338488, train_mrr_ema=0.279778, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.250105
Sat, 18 May 2019 17:50:44 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0110, max_total_steps: 100000000
Sat, 18 May 2019 17:51:17 unsupervised_train.py[line:356] INFO Iter: 0120, train_loss=15.295518, train_mrr=0.303994, train_mrr_ema=0.282548, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.255696
Sat, 18 May 2019 17:51:17 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0120, max_total_steps: 100000000
Sat, 18 May 2019 17:52:01 unsupervised_train.py[line:356] INFO Iter: 0130, train_loss=15.218338, train_mrr=0.279444, train_mrr_ema=0.285177, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.340111
Sat, 18 May 2019 17:52:01 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0130, max_total_steps: 100000000
Sat, 18 May 2019 17:52:38 unsupervised_train.py[line:356] INFO Iter: 0140, train_loss=15.273088, train_mrr=0.307719, train_mrr_ema=0.289499, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.363988
Sat, 18 May 2019 17:52:38 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0140, max_total_steps: 100000000
Sat, 18 May 2019 17:53:08 unsupervised_train.py[line:356] INFO Iter: 0150, train_loss=15.071864, train_mrr=0.309642, train_mrr_ema=0.292595, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.344784
Sat, 18 May 2019 17:53:08 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0150, max_total_steps: 100000000
Sat, 18 May 2019 17:53:43 unsupervised_train.py[line:356] INFO Iter: 0160, train_loss=15.280428, train_mrr=0.310513, train_mrr_ema=0.295319, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.349447
Sat, 18 May 2019 17:53:43 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0160, max_total_steps: 100000000
Sat, 18 May 2019 17:54:25 unsupervised_train.py[line:356] INFO Iter: 0170, train_loss=14.865897, train_mrr=0.314683, train_mrr_ema=0.297971, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.401053
Sat, 18 May 2019 17:54:25 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0170, max_total_steps: 100000000
Sat, 18 May 2019 17:55:02 unsupervised_train.py[line:356] INFO Iter: 0180, train_loss=14.894430, train_mrr=0.324095, train_mrr_ema=0.301090, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.419542
Sat, 18 May 2019 17:55:02 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0180, max_total_steps: 100000000
Sat, 18 May 2019 17:55:40 unsupervised_train.py[line:356] INFO Iter: 0190, train_loss=14.588139, train_mrr=0.367684, train_mrr_ema=0.304401, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.436830
Sat, 18 May 2019 17:55:40 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0190, max_total_steps: 100000000
Sat, 18 May 2019 17:56:15 unsupervised_train.py[line:356] INFO Iter: 0200, train_loss=14.762083, train_mrr=0.329045, train_mrr_ema=0.306861, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.443199
Sat, 18 May 2019 17:56:15 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0200, max_total_steps: 100000000
Sat, 18 May 2019 17:56:47 unsupervised_train.py[line:356] INFO Iter: 0210, train_loss=14.951770, train_mrr=0.339200, train_mrr_ema=0.308884, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.430886
Sat, 18 May 2019 17:56:47 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0210, max_total_steps: 100000000
Sat, 18 May 2019 17:57:20 unsupervised_train.py[line:356] INFO Iter: 0220, train_loss=15.249232, train_mrr=0.332010, train_mrr_ema=0.311395, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.424434
Sat, 18 May 2019 17:57:20 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0220, max_total_steps: 100000000
Sat, 18 May 2019 17:57:42 unsupervised_train.py[line:379] INFO ######## Saving embedding data to file ##########
Sat, 18 May 2019 17:57:44 unsupervised_train.py[line:131] INFO Start saving embedding for succeed tasks
Sat, 18 May 2019 17:57:44 unsupervised_train.py[line:151] INFO Number of nodes in set U: 734
Sat, 18 May 2019 17:57:44 unsupervised_train.py[line:433] INFO ############ Embedding data saved #############
Sat, 18 May 2019 18:10:19 utils.py[line:43] INFO class map loaded
Sat, 18 May 2019 18:10:19 utils.py[line:59] INFO bad nodes removed
Sat, 18 May 2019 18:10:20 utils.py[line:78] INFO Normalized
Sat, 18 May 2019 18:10:20 utils.py[line:93] INFO data all loaded
Sat, 18 May 2019 18:10:20 unsupervised_train.py[line:443] INFO start training
Sat, 18 May 2019 18:10:20 unsupervised_train.py[line:192] INFO edge minibatch
Sat, 18 May 2019 18:10:21 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/10.Federated-Learning-with-DPASGD/sourcecode/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Sat, 18 May 2019 18:10:21 unsupervised_train.py[line:202] INFO choose model
Sat, 18 May 2019 18:10:21 deprecation.py[line:506] WARNING From /Users/chaoyanghe/Presentation/12.GraphNeuralNetwork/sourcecode/bipartite-graph-learning/GraphSage/graphsage/aggregators.py:46: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Sat, 18 May 2019 18:10:21 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/12.GraphNeuralNetwork/sourcecode/bipartite-graph-learning/GraphSage/graphsage/models.py:407: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
Sat, 18 May 2019 18:10:21 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/10.Federated-Learning-with-DPASGD/sourcecode/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Sat, 18 May 2019 18:10:22 unsupervised_train.py[line:314] INFO training epoch: 1
Sat, 18 May 2019 18:10:27 unsupervised_train.py[line:356] INFO Iter: 0000, train_loss=18.867777, train_mrr=0.230752, train_mrr_ema=0.230752, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.784228
Sat, 18 May 2019 18:10:27 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0000, max_total_steps: 100000000
Sat, 18 May 2019 18:10:59 unsupervised_train.py[line:356] INFO Iter: 0010, train_loss=17.705729, train_mrr=0.307270, train_mrr_ema=0.234536, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.317503
Sat, 18 May 2019 18:10:59 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0010, max_total_steps: 100000000
Sat, 18 May 2019 18:11:31 unsupervised_train.py[line:356] INFO Iter: 0020, train_loss=17.695002, train_mrr=0.305525, train_mrr_ema=0.237693, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.260132
Sat, 18 May 2019 18:11:31 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0020, max_total_steps: 100000000
Sat, 18 May 2019 18:12:02 unsupervised_train.py[line:356] INFO Iter: 0030, train_loss=16.926075, train_mrr=0.269394, train_mrr_ema=0.240122, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.226404
Sat, 18 May 2019 18:12:02 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0030, max_total_steps: 100000000
Sat, 18 May 2019 18:12:37 utils.py[line:43] INFO class map loaded
Sat, 18 May 2019 18:12:37 utils.py[line:59] INFO bad nodes removed
Sat, 18 May 2019 18:12:37 utils.py[line:78] INFO Normalized
Sat, 18 May 2019 18:12:37 utils.py[line:93] INFO data all loaded
Sat, 18 May 2019 18:12:37 unsupervised_train.py[line:443] INFO start training
Sat, 18 May 2019 18:12:37 unsupervised_train.py[line:192] INFO edge minibatch
Sat, 18 May 2019 18:12:38 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/10.Federated-Learning-with-DPASGD/sourcecode/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Sat, 18 May 2019 18:12:38 unsupervised_train.py[line:202] INFO choose model
Sat, 18 May 2019 18:12:38 deprecation.py[line:506] WARNING From /Users/chaoyanghe/Presentation/12.GraphNeuralNetwork/sourcecode/bipartite-graph-learning/GraphSage/graphsage/aggregators.py:46: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Sat, 18 May 2019 18:12:38 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/12.GraphNeuralNetwork/sourcecode/bipartite-graph-learning/GraphSage/graphsage/models.py:407: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
Sat, 18 May 2019 18:12:38 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/10.Federated-Learning-with-DPASGD/sourcecode/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Sat, 18 May 2019 18:12:39 unsupervised_train.py[line:314] INFO training epoch: 1
Sat, 18 May 2019 18:12:44 unsupervised_train.py[line:356] INFO Iter: 0000, train_loss=18.883776, train_mrr=0.256847, train_mrr_ema=0.256847, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=5.071279
Sat, 18 May 2019 18:12:44 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0000, max_total_steps: 100000000
Sat, 18 May 2019 18:13:24 unsupervised_train.py[line:356] INFO Iter: 0010, train_loss=17.626137, train_mrr=0.325613, train_mrr_ema=0.258557, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.037700
Sat, 18 May 2019 18:13:24 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0010, max_total_steps: 100000000
Sat, 18 May 2019 18:14:01 unsupervised_train.py[line:356] INFO Iter: 0020, train_loss=17.723394, train_mrr=0.290433, train_mrr_ema=0.259922, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.904596
Sat, 18 May 2019 18:14:01 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0020, max_total_steps: 100000000
Sat, 18 May 2019 18:14:42 unsupervised_train.py[line:356] INFO Iter: 0030, train_loss=17.082769, train_mrr=0.288235, train_mrr_ema=0.260915, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.938568
Sat, 18 May 2019 18:14:42 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0030, max_total_steps: 100000000
Sat, 18 May 2019 18:15:21 unsupervised_train.py[line:356] INFO Iter: 0040, train_loss=17.094378, train_mrr=0.280164, train_mrr_ema=0.262632, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.928186
Sat, 18 May 2019 18:15:21 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0040, max_total_steps: 100000000
Sat, 18 May 2019 18:16:04 unsupervised_train.py[line:356] INFO Iter: 0050, train_loss=16.262554, train_mrr=0.311942, train_mrr_ema=0.265519, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.001554
Sat, 18 May 2019 18:16:04 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0050, max_total_steps: 100000000
Sat, 18 May 2019 18:16:46 unsupervised_train.py[line:356] INFO Iter: 0060, train_loss=15.946446, train_mrr=0.291402, train_mrr_ema=0.268345, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.047618
Sat, 18 May 2019 18:16:46 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0060, max_total_steps: 100000000
Sat, 18 May 2019 18:17:34 unsupervised_train.py[line:356] INFO Iter: 0070, train_loss=16.007929, train_mrr=0.288019, train_mrr_ema=0.271741, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.142993
Sat, 18 May 2019 18:17:34 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0070, max_total_steps: 100000000
Sat, 18 May 2019 18:18:17 unsupervised_train.py[line:356] INFO Iter: 0080, train_loss=15.750805, train_mrr=0.312824, train_mrr_ema=0.274106, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.171797
Sat, 18 May 2019 18:18:17 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0080, max_total_steps: 100000000
Sat, 18 May 2019 18:18:49 unsupervised_train.py[line:356] INFO Iter: 0090, train_loss=15.419034, train_mrr=0.300672, train_mrr_ema=0.276862, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=4.055704
Sat, 18 May 2019 18:18:49 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0090, max_total_steps: 100000000
Sat, 18 May 2019 18:19:17 unsupervised_train.py[line:356] INFO Iter: 0100, train_loss=15.034937, train_mrr=0.312438, train_mrr_ema=0.279598, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.939809
Sat, 18 May 2019 18:19:17 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0100, max_total_steps: 100000000
Sat, 18 May 2019 18:19:51 unsupervised_train.py[line:356] INFO Iter: 0110, train_loss=15.197907, train_mrr=0.330604, train_mrr_ema=0.283410, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.885696
Sat, 18 May 2019 18:19:51 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0110, max_total_steps: 100000000
Sat, 18 May 2019 18:20:31 unsupervised_train.py[line:356] INFO Iter: 0120, train_loss=15.209539, train_mrr=0.309388, train_mrr_ema=0.285406, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.894997
Sat, 18 May 2019 18:20:31 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0120, max_total_steps: 100000000
Sat, 18 May 2019 18:21:10 unsupervised_train.py[line:356] INFO Iter: 0130, train_loss=15.188491, train_mrr=0.301967, train_mrr_ema=0.288309, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.896138
Sat, 18 May 2019 18:21:10 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0130, max_total_steps: 100000000
Sat, 18 May 2019 18:21:50 unsupervised_train.py[line:356] INFO Iter: 0140, train_loss=15.323822, train_mrr=0.294725, train_mrr_ema=0.291501, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.906989
Sat, 18 May 2019 18:21:50 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0140, max_total_steps: 100000000
Sat, 18 May 2019 18:22:31 unsupervised_train.py[line:356] INFO Iter: 0150, train_loss=15.025448, train_mrr=0.310673, train_mrr_ema=0.294970, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.918365
Sat, 18 May 2019 18:22:31 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0150, max_total_steps: 100000000
Sat, 18 May 2019 18:23:12 unsupervised_train.py[line:356] INFO Iter: 0160, train_loss=15.374863, train_mrr=0.305682, train_mrr_ema=0.297437, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.927783
Sat, 18 May 2019 18:23:12 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0160, max_total_steps: 100000000
Sat, 18 May 2019 18:23:53 unsupervised_train.py[line:356] INFO Iter: 0170, train_loss=14.854277, train_mrr=0.312206, train_mrr_ema=0.299306, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.940405
Sat, 18 May 2019 18:23:53 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0170, max_total_steps: 100000000
Sat, 18 May 2019 18:24:31 unsupervised_train.py[line:356] INFO Iter: 0180, train_loss=14.878995, train_mrr=0.323044, train_mrr_ema=0.300906, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.928308
Sat, 18 May 2019 18:24:31 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0180, max_total_steps: 100000000
Sat, 18 May 2019 18:25:14 unsupervised_train.py[line:356] INFO Iter: 0190, train_loss=14.612398, train_mrr=0.352281, train_mrr_ema=0.303731, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.951944
Sat, 18 May 2019 18:25:14 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0190, max_total_steps: 100000000
Sat, 18 May 2019 18:25:56 unsupervised_train.py[line:356] INFO Iter: 0200, train_loss=14.672085, train_mrr=0.364682, train_mrr_ema=0.306984, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.963094
Sat, 18 May 2019 18:25:56 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0200, max_total_steps: 100000000
Sat, 18 May 2019 18:26:38 unsupervised_train.py[line:356] INFO Iter: 0210, train_loss=14.901584, train_mrr=0.335656, train_mrr_ema=0.309108, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.974504
Sat, 18 May 2019 18:26:38 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0210, max_total_steps: 100000000
Sat, 18 May 2019 18:27:13 unsupervised_train.py[line:356] INFO Iter: 0220, train_loss=15.171124, train_mrr=0.359527, train_mrr_ema=0.311812, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.950835
Sat, 18 May 2019 18:27:13 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0220, max_total_steps: 100000000
Sat, 18 May 2019 18:27:35 unsupervised_train.py[line:379] INFO ######## Saving embedding data to file ##########
Sat, 18 May 2019 18:27:37 unsupervised_train.py[line:131] INFO Start saving embedding for succeed tasks
Sat, 18 May 2019 18:27:37 unsupervised_train.py[line:151] INFO Number of nodes in set U: 734
Sat, 18 May 2019 18:27:37 unsupervised_train.py[line:433] INFO ############ Embedding data saved #############
Sat, 18 May 2019 18:47:34 utils.py[line:43] INFO class map loaded
Sat, 18 May 2019 18:47:34 utils.py[line:59] INFO bad nodes removed
Sat, 18 May 2019 18:47:34 utils.py[line:78] INFO Normalized
Sat, 18 May 2019 18:47:35 utils.py[line:93] INFO data all loaded
Sat, 18 May 2019 18:47:35 unsupervised_train.py[line:443] INFO start training
Sat, 18 May 2019 18:47:35 unsupervised_train.py[line:192] INFO edge minibatch
Sat, 18 May 2019 18:47:36 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/10.Federated-Learning-with-DPASGD/sourcecode/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Sat, 18 May 2019 18:47:36 unsupervised_train.py[line:202] INFO choose model
Sat, 18 May 2019 18:47:36 deprecation.py[line:506] WARNING From /Users/chaoyanghe/Presentation/12.GraphNeuralNetwork/sourcecode/bipartite-graph-learning/GraphSage/graphsage/aggregators.py:46: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Sat, 18 May 2019 18:47:36 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/12.GraphNeuralNetwork/sourcecode/bipartite-graph-learning/GraphSage/graphsage/models.py:407: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
Sat, 18 May 2019 18:47:36 deprecation.py[line:323] WARNING From /Users/chaoyanghe/Presentation/10.Federated-Learning-with-DPASGD/sourcecode/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Sat, 18 May 2019 18:47:38 unsupervised_train.py[line:314] INFO training epoch: 1
Sat, 18 May 2019 18:47:43 unsupervised_train.py[line:356] INFO Iter: 0000, train_loss=18.973951, train_mrr=0.241538, train_mrr_ema=0.241538, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=5.070535
Sat, 18 May 2019 18:47:43 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0000, max_total_steps: 100000000
Sat, 18 May 2019 18:48:14 unsupervised_train.py[line:356] INFO Iter: 0010, train_loss=17.679445, train_mrr=0.267637, train_mrr_ema=0.243370, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.300527
Sat, 18 May 2019 18:48:14 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0010, max_total_steps: 100000000
Sat, 18 May 2019 18:48:46 unsupervised_train.py[line:356] INFO Iter: 0020, train_loss=17.844376, train_mrr=0.279843, train_mrr_ema=0.245812, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.275045
Sat, 18 May 2019 18:48:46 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0020, max_total_steps: 100000000
Sat, 18 May 2019 18:49:30 unsupervised_train.py[line:356] INFO Iter: 0030, train_loss=17.114595, train_mrr=0.282578, train_mrr_ema=0.247748, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=3.639775
Sat, 18 May 2019 18:49:30 unsupervised_train.py[line:358] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0030, max_total_steps: 100000000
Sat, 18 May 2019 23:03:34 utils.py[line:43] INFO class map loaded
Sat, 18 May 2019 23:03:34 utils.py[line:59] INFO bad nodes removed
Sat, 18 May 2019 23:03:34 utils.py[line:78] INFO Normalized
Sat, 18 May 2019 23:03:34 utils.py[line:93] INFO data all loaded
Sat, 18 May 2019 23:03:34 unsupervised_train.py[line:448] INFO start training
Sat, 18 May 2019 23:03:35 unsupervised_train.py[line:196] INFO edge minibatch
Sat, 18 May 2019 23:03:35 deprecation.py[line:323] WARNING From /Users/apple/Documents/P1_Decentralized_Multitask/Leaf_New_2.0/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Sat, 18 May 2019 23:03:35 unsupervised_train.py[line:206] INFO choose model
Sat, 18 May 2019 23:03:35 deprecation.py[line:506] WARNING From /Users/apple/Documents/P4_Graph/merge_sourcecode/bipartite-graph-learning/GraphSage/graphsage/aggregators.py:104: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
Sat, 18 May 2019 23:03:36 deprecation.py[line:323] WARNING From /Users/apple/Documents/P4_Graph/merge_sourcecode/bipartite-graph-learning/GraphSage/graphsage/models.py:407: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Deprecated in favor of operator or tf.math.divide.
Sat, 18 May 2019 23:03:36 deprecation.py[line:323] WARNING From /Users/apple/Documents/P1_Decentralized_Multitask/Leaf_New_2.0/venv/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Sat, 18 May 2019 23:03:37 unsupervised_train.py[line:319] INFO training epoch: 1
Sat, 18 May 2019 23:04:00 unsupervised_train.py[line:361] INFO Iter: 0000, train_loss=18.958540, train_mrr=0.635380, train_mrr_ema=0.635380, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=22.194310
Sat, 18 May 2019 23:04:00 unsupervised_train.py[line:363] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0000, max_total_steps: 100000000
Sat, 18 May 2019 23:05:16 unsupervised_train.py[line:361] INFO Iter: 0010, train_loss=19.361584, train_mrr=0.595981, train_mrr_ema=0.634442, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=8.982238
Sat, 18 May 2019 23:05:16 unsupervised_train.py[line:363] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0010, max_total_steps: 100000000
Sat, 18 May 2019 23:06:20 unsupervised_train.py[line:361] INFO Iter: 0020, train_loss=17.261528, train_mrr=0.716181, train_mrr_ema=0.636068, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=7.764136
Sat, 18 May 2019 23:06:20 unsupervised_train.py[line:363] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0020, max_total_steps: 100000000
Sat, 18 May 2019 23:07:20 unsupervised_train.py[line:361] INFO Iter: 0030, train_loss=17.465382, train_mrr=0.669785, train_mrr_ema=0.638610, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=7.169236
Sat, 18 May 2019 23:07:20 unsupervised_train.py[line:363] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0030, max_total_steps: 100000000
Sat, 18 May 2019 23:08:18 unsupervised_train.py[line:361] INFO Iter: 0040, train_loss=16.325979, train_mrr=0.640338, train_mrr_ema=0.640830, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=6.839982
Sat, 18 May 2019 23:08:18 unsupervised_train.py[line:363] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0040, max_total_steps: 100000000
Sat, 18 May 2019 23:09:29 unsupervised_train.py[line:361] INFO Iter: 0050, train_loss=15.918473, train_mrr=0.683468, train_mrr_ema=0.644498, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=6.885265
Sat, 18 May 2019 23:09:29 unsupervised_train.py[line:363] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0050, max_total_steps: 100000000
Sat, 18 May 2019 23:10:31 unsupervised_train.py[line:361] INFO Iter: 0060, train_loss=15.923645, train_mrr=0.680208, train_mrr_ema=0.647223, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=6.776016
Sat, 18 May 2019 23:10:31 unsupervised_train.py[line:363] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0060, max_total_steps: 100000000
Sat, 18 May 2019 23:11:52 unsupervised_train.py[line:361] INFO Iter: 0070, train_loss=15.357291, train_mrr=0.680067, train_mrr_ema=0.650243, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=6.961644
Sat, 18 May 2019 23:11:52 unsupervised_train.py[line:363] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0070, max_total_steps: 100000000
Sat, 18 May 2019 23:13:04 unsupervised_train.py[line:361] INFO Iter: 0080, train_loss=15.195654, train_mrr=0.706095, train_mrr_ema=0.654055, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=6.998718
Sat, 18 May 2019 23:13:04 unsupervised_train.py[line:363] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0080, max_total_steps: 100000000
Sat, 18 May 2019 23:14:08 unsupervised_train.py[line:361] INFO Iter: 0090, train_loss=15.104689, train_mrr=0.649033, train_mrr_ema=0.657023, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=6.923967
Sat, 18 May 2019 23:14:08 unsupervised_train.py[line:363] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0090, max_total_steps: 100000000
Sat, 18 May 2019 23:15:34 unsupervised_train.py[line:361] INFO Iter: 0100, train_loss=14.666912, train_mrr=0.714775, train_mrr_ema=0.660738, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=7.092943
Sat, 18 May 2019 23:15:34 unsupervised_train.py[line:363] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0100, max_total_steps: 100000000
Sat, 18 May 2019 23:16:50 unsupervised_train.py[line:361] INFO Iter: 0110, train_loss=14.937395, train_mrr=0.665479, train_mrr_ema=0.663631, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=7.141208
Sat, 18 May 2019 23:16:50 unsupervised_train.py[line:363] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0110, max_total_steps: 100000000
Sat, 18 May 2019 23:18:09 unsupervised_train.py[line:361] INFO Iter: 0120, train_loss=14.726953, train_mrr=0.664084, train_mrr_ema=0.665857, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=7.205276
Sat, 18 May 2019 23:18:09 unsupervised_train.py[line:363] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0120, max_total_steps: 100000000
Sat, 18 May 2019 23:19:18 unsupervised_train.py[line:361] INFO Iter: 0130, train_loss=14.580526, train_mrr=0.717691, train_mrr_ema=0.669266, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=7.178362
Sat, 18 May 2019 23:19:18 unsupervised_train.py[line:363] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0130, max_total_steps: 100000000
Sat, 18 May 2019 23:20:35 unsupervised_train.py[line:361] INFO Iter: 0140, train_loss=14.740693, train_mrr=0.726207, train_mrr_ema=0.672329, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=7.217450
Sat, 18 May 2019 23:20:35 unsupervised_train.py[line:363] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0140, max_total_steps: 100000000
Sat, 18 May 2019 23:22:07 unsupervised_train.py[line:361] INFO Iter: 0150, train_loss=14.626487, train_mrr=0.719269, train_mrr_ema=0.676367, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=7.347732
Sat, 18 May 2019 23:22:07 unsupervised_train.py[line:363] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0150, max_total_steps: 100000000
Sat, 18 May 2019 23:23:40 unsupervised_train.py[line:361] INFO Iter: 0160, train_loss=14.651386, train_mrr=0.738721, train_mrr_ema=0.679856, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=7.464887
Sat, 18 May 2019 23:23:40 unsupervised_train.py[line:363] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0160, max_total_steps: 100000000
Sat, 18 May 2019 23:25:11 unsupervised_train.py[line:361] INFO Iter: 0170, train_loss=14.534501, train_mrr=0.729456, train_mrr_ema=0.682634, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=7.564635
Sat, 18 May 2019 23:25:11 unsupervised_train.py[line:363] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0170, max_total_steps: 100000000
Sat, 18 May 2019 23:26:22 unsupervised_train.py[line:361] INFO Iter: 0180, train_loss=14.547662, train_mrr=0.682513, train_mrr_ema=0.684047, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=7.539135
Sat, 18 May 2019 23:26:22 unsupervised_train.py[line:363] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0180, max_total_steps: 100000000
Sat, 18 May 2019 23:27:58 unsupervised_train.py[line:361] INFO Iter: 0190, train_loss=14.544281, train_mrr=0.705440, train_mrr_ema=0.687556, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=7.643352
Sat, 18 May 2019 23:27:58 unsupervised_train.py[line:363] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0190, max_total_steps: 100000000
Sat, 18 May 2019 23:29:32 unsupervised_train.py[line:361] INFO Iter: 0200, train_loss=14.473722, train_mrr=0.744612, train_mrr_ema=0.689424, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=7.734083
Sat, 18 May 2019 23:29:32 unsupervised_train.py[line:363] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0200, max_total_steps: 100000000
Sat, 18 May 2019 23:31:11 unsupervised_train.py[line:361] INFO Iter: 0210, train_loss=14.531945, train_mrr=0.723154, train_mrr_ema=0.691354, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=7.837458
Sat, 18 May 2019 23:31:11 unsupervised_train.py[line:363] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0210, max_total_steps: 100000000
Sat, 18 May 2019 23:32:16 unsupervised_train.py[line:361] INFO Iter: 0220, train_loss=14.522128, train_mrr=0.700503, train_mrr_ema=0.693327, val_loss=0inf, val_mrr=0nan, val_mrr_ema=0nan, time=7.776187
Sat, 18 May 2019 23:32:16 unsupervised_train.py[line:363] INFO Epochs: 0000, Max epochs: 0001, total_steps: 0220, max_total_steps: 100000000
Sat, 18 May 2019 23:33:06 unsupervised_train.py[line:384] INFO ######## Saving embedding data to file ##########
Sat, 18 May 2019 23:33:12 unsupervised_train.py[line:132] INFO Start saving embedding for succeed tasks
Sat, 18 May 2019 23:33:12 unsupervised_train.py[line:152] INFO Number of nodes in set U: 734
Sat, 18 May 2019 23:33:12 unsupervised_train.py[line:163] INFO output file = ./../out/graphsage/cora/
Sat, 18 May 2019 23:33:12 unsupervised_train.py[line:438] INFO ############ Embedding data saved #############
